variables:
  GIT_SUBMODULE_STRATEGY: recursive

stages:
  - Tag container
  - Build container
  - Lint code
  - Build code
  - Test code
  - Static analysis on code

image: registry.gitlab.com/project-march/march:$CI_COMMIT_BRANCH

# Allow each branch to run their own container. This allows a branch to add
# dependencies to their package.xml and use them as expected. This process works as
# follows:
# 1. If an image with the tag of the current branch is not available, the base image
#   is pulled and tagged as the image for this branch.
# 2. If there are changes to the Dockerfile or to a package.xml file, rebuild the
#   container. This will use remote caches from GitLab to speed up the process.
container:tag:
  stage: Tag container
  image: quay.io/podman/stable
  variables:
    GIT_CHECKOUT: "true"
  before_script:
    - podman login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY


  script:
    - if ! podman manifest inspect $CI_REGISTRY_IMAGE:$CI_COMMIT_BRANCH; then podman pull $CI_REGISTRY_IMAGE:$CI_DEFAULT_BRANCH && podman tag $CI_REGISTRY_IMAGE:$CI_DEFAULT_BRANCH $CI_REGISTRY_IMAGE:$CI_COMMIT_BRANCH && podman push $CI_REGISTRY_IMAGE:$CI_COMMIT_BRANCH; fi;

container:build:
  stage: Build container
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  script:
    - mkdir -p /kaniko/.docker
    # Equivalent to `docker login` but without installing docker"
    - echo "{\"auths\":{\"$CI_REGISTRY\":{\"username\":\"$CI_REGISTRY_USER\",\"password\":\"$CI_REGISTRY_PASSWORD\"}}}" > /kaniko/.docker/config.json
    # The kaniko executor from https://github.com/GoogleContainerTools/kaniko
    # Information about all the parameters can be found there.
    - /kaniko/executor --cache=true --dockerfile $CI_PROJECT_DIR/Dockerfile --destination $CI_REGISTRY_IMAGE:$CI_COMMIT_BRANCH --cleanup
  rules:
    - if: '$CI_COMMIT_BRANCH'
      changes:
        - Dockerfile

# Runs a linter on the code to see if the code style is consistent and to avoid common
# mistakes
flake8:
  stage: Lint code
  script:
    - python3 -m flakehell lint --suppress-none-returning --format=gitlab --output-file flakehell.json
  artifacts:
    reports:
      codequality: flakehell.json
  allow_failure: true

noetic:build:
  stage: Build code
  artifacts:
    paths:
      - ros1/build/
      - ros1/install/
      - ros1/log/
  script:
    - cd ros1/
    - source /opt/ros/noetic/local_setup.bash && colcon build --cmake-args "-DCMAKE_EXPORT_COMPILE_COMMANDS=1" --event-handlers console_direct+

foxy:build:
  stage: Build code
  artifacts:
    paths:
      - ros2/build/
      - ros2/install/
      - ros2/log/
  script:
    - cd ros2/
    - source /opt/ros/foxy/local_setup.bash && colcon build --cmake-args "-DCMAKE_EXPORT_COMPILE_COMMANDS=1" --event-handlers console_direct+

noetic:test:
  stage: Test code
  dependencies:
    - noetic:build
  needs: ["noetic:build"]
  script:
    - cd ros1/
    - source /opt/ros/noetic/local_setup.bash && source install/local_setup.bash && colcon test --event-handlers console_direct+
    - colcon test-result --verbose

foxy:test:
  stage: Test code
  dependencies:
    - foxy:build
  needs: ["foxy:build"]
  script:
    - cd ros2/
    - source /opt/ros/foxy/local_setup.bash && source install/local_setup.bash && colcon test --event-handlers console_direct+
    - colcon test-result --verbose

noetic:clang_tidy:
  stage: Static analysis on code
  dependencies:
    - noetic:build
  needs: ["noetic:build"]
  script:
    - cd ros1/
    - find src -name '*.hpp' -or -name '*.h' -or -name '*.cpp' | xargs -L1 -P$(getconf _NPROCESSORS_ONLN) -I{} -- clang-tidy -p build {} 2> /dev/null
  only:
    changes:
      - "ros1/**/*.{hpp,h,cpp}"
  allow_failure: true

foxy:clang_tidy:
  stage: Static analysis on code
  dependencies:
    - foxy:build
  needs: ["foxy:build"]
  script:
    - cd ros2/
    - find src -name '*.hpp' -or -name '*.h' -or -name '*.cpp' | xargs -L1 -P$(getconf _NPROCESSORS_ONLN) -I{} -- clang-tidy -p build {} 2> /dev/null
  only:
    changes:
      - "ros2/**/*.{hpp,h,cpp}"
  allow_failure: true
